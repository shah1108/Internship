{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d410a479",
   "metadata": {},
   "source": [
    "# ASSIGNMENT-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b13b5b8",
   "metadata": {},
   "source": [
    "## WEB SCRAPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89312026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.4.3)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (1.26.7)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (0.21.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: outcome in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.14.6)\n",
      "Requirement already satisfied: idna in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.2)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\admin\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb070ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException,InvalidArgumentException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import re\n",
    "import requests\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8231f845",
   "metadata": {},
   "source": [
    "Q1. Scrape the details of most viewed videos on YouTube from Wikipedia.                                                         \n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos                                                         \n",
    "You need to find following details:                                                                                             \n",
    "A) Rank                                                                                                                         \n",
    "B) Name                                                                                                                         \n",
    "C) Artist                                                                                                                       \n",
    "D) Upload date                                                                                                                  E) Views                                                                                                                                                                                                                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dbf369b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to driver\n",
    "driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "time.sleep(2)\n",
    "# opening site\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49b7a9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list to store data\n",
    "Rank = []\n",
    "Name = []\n",
    "Artist = []\n",
    "Upload_date = []\n",
    "Views = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "39ba89e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping whole data in one step \n",
    "rank = [] # to store whole data then i will separate them\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//td')[2:]:\n",
    "        rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    rank.append('-')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7d6bb91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting rank from the list contining whole info\n",
    "Rank = rank[0::6][0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7f764a53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extractin name of video\n",
    "Name = rank[1::6][0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fb7fc0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting Artist Name\n",
    "Artist = rank[2::6][0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "11c8f9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting views\n",
    "Views = rank[3::6][0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f05697ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting upload date\n",
    "Upload_date = rank[4::6][0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "39238830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most viewed videos on YouTube from Wikipedia\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RANK</th>\n",
       "      <th>VIDEO NAME</th>\n",
       "      <th>ATRIST</th>\n",
       "      <th>VIEWS(BILLIONS)</th>\n",
       "      <th>UPLOAD DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[3]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>11.40</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[6]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>7.98</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[12]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>6.47</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Shape of You\"[13]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>5.81</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"See You Again\"[15]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>5.64</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"Bath Song\"[20]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>5.63</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[21]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>4.90</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Uptown Funk\"[22]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>4.70</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[23]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>4.65</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Gangnam Style\"[24]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>4.55</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[29]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.51</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Wheels on the Bus\"[30]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>4.40</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[31]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>4.07</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Sugar\"[32]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.76</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Roar\"[33]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.66</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[34]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.65</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Sorry\"[35]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.59</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Axel F\"[36]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>3.52</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Thinking Out Loud\"[37]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.50</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[38]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>3.38</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Dark Horse\"[39]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.35</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Faded\"[40]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.34</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Girls Like You\"[41]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.33</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Let Her Go\"[42]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.30</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Bailando\"[43]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>3.27</td>\n",
       "      <td>April 11, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Lean On\"[44]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>3.26</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Perfect\"[45]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.26</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[46]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.25</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Shake It Off\"[47]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>3.21</td>\n",
       "      <td>August 18, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[48]</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>3.17</td>\n",
       "      <td>January 26, 2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RANK                                       VIDEO NAME  \\\n",
       "1    1.                            \"Baby Shark Dance\"[3]   \n",
       "2    2.                                   \"Despacito\"[6]   \n",
       "3    3.                       \"Johny Johny Yes Papa\"[12]   \n",
       "4    4.                               \"Shape of You\"[13]   \n",
       "5    5.                              \"See You Again\"[15]   \n",
       "6    6.                                  \"Bath Song\"[20]   \n",
       "7    7.                \"Phonics Song with Two Words\"[21]   \n",
       "8    8.                                \"Uptown Funk\"[22]   \n",
       "9    9.  \"Learning Colors – Colorful Eggs on a Farm\"[23]   \n",
       "10  10.                              \"Gangnam Style\"[24]   \n",
       "11  11.   \"Masha and the Bear – Recipe for Disaster\"[29]   \n",
       "12  12.                          \"Wheels on the Bus\"[30]   \n",
       "13  13.                             \"Dame Tu Cosita\"[31]   \n",
       "14  14.                                      \"Sugar\"[32]   \n",
       "15  15.                                       \"Roar\"[33]   \n",
       "16  16.                             \"Counting Stars\"[34]   \n",
       "17  17.                                      \"Sorry\"[35]   \n",
       "18  18.                                     \"Axel F\"[36]   \n",
       "19  18.                          \"Thinking Out Loud\"[37]   \n",
       "20  20.                        \"Baa Baa Black Sheep\"[38]   \n",
       "21  21.                                 \"Dark Horse\"[39]   \n",
       "22  22.                                      \"Faded\"[40]   \n",
       "23  23.                             \"Girls Like You\"[41]   \n",
       "24  24.                                 \"Let Her Go\"[42]   \n",
       "25  25.                                   \"Bailando\"[43]   \n",
       "26  26.                                    \"Lean On\"[44]   \n",
       "27  27.                                    \"Perfect\"[45]   \n",
       "28  28.           \"Waka Waka (This Time for Africa)\"[46]   \n",
       "29  29.                               \"Shake It Off\"[47]   \n",
       "30  30.          \"Humpty the train on a fruits ride\"[48]   \n",
       "\n",
       "                                           ATRIST VIEWS(BILLIONS)  \\\n",
       "1     Pinkfong Baby Shark - Kids' Songs & Stories           11.40   \n",
       "2                                      Luis Fonsi            7.98   \n",
       "3                                     LooLoo Kids            6.47   \n",
       "4                                      Ed Sheeran            5.81   \n",
       "5                                     Wiz Khalifa            5.64   \n",
       "6                      Cocomelon – Nursery Rhymes            5.63   \n",
       "7                                       ChuChu TV            4.90   \n",
       "8                                     Mark Ronson            4.70   \n",
       "9                                     Miroshka TV            4.65   \n",
       "10                                            Psy            4.55   \n",
       "11                                     Get Movies            4.51   \n",
       "12                     Cocomelon – Nursery Rhymes            4.40   \n",
       "13                                      El Chombo            4.07   \n",
       "14                                       Maroon 5            3.76   \n",
       "15                                     Katy Perry            3.66   \n",
       "16                                    OneRepublic            3.65   \n",
       "17                                  Justin Bieber            3.59   \n",
       "18                                     Crazy Frog            3.52   \n",
       "19                                     Ed Sheeran            3.50   \n",
       "20                     Cocomelon – Nursery Rhymes            3.38   \n",
       "21                                     Katy Perry            3.35   \n",
       "22                                    Alan Walker            3.34   \n",
       "23                                       Maroon 5            3.33   \n",
       "24                                      Passenger            3.30   \n",
       "25                               Enrique Iglesias            3.27   \n",
       "26                                    Major Lazer            3.26   \n",
       "27                                     Ed Sheeran            3.26   \n",
       "28                                        Shakira            3.25   \n",
       "29                                   Taylor Swift            3.21   \n",
       "30  Kiddiestv Hindi – Nursery Rhymes & Kids Songs            3.17   \n",
       "\n",
       "          UPLOAD DATE  \n",
       "1       June 17, 2016  \n",
       "2    January 12, 2017  \n",
       "3     October 8, 2016  \n",
       "4    January 30, 2017  \n",
       "5       April 6, 2015  \n",
       "6         May 2, 2018  \n",
       "7       March 6, 2014  \n",
       "8   November 19, 2014  \n",
       "9   February 27, 2018  \n",
       "10      July 15, 2012  \n",
       "11   January 31, 2012  \n",
       "12       May 24, 2018  \n",
       "13      April 5, 2018  \n",
       "14   January 14, 2015  \n",
       "15  September 5, 2013  \n",
       "16       May 31, 2013  \n",
       "17   October 22, 2015  \n",
       "18      June 16, 2009  \n",
       "19    October 7, 2014  \n",
       "20      June 25, 2018  \n",
       "21  February 20, 2014  \n",
       "22   December 3, 2015  \n",
       "23       May 31, 2018  \n",
       "24      July 25, 2012  \n",
       "25     April 11, 2014  \n",
       "26     March 22, 2015  \n",
       "27   November 9, 2017  \n",
       "28       June 4, 2010  \n",
       "29    August 18, 2014  \n",
       "30   January 26, 2018  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe\n",
    "df = pd.DataFrame({\"RANK\":Rank,\"VIDEO NAME\":Name,\"ATRIST\":Artist,\"VIEWS(BILLIONS)\":Views,\"UPLOAD DATE\":Upload_date},index=list(range(1,len(Upload_date)+1)))\n",
    "print(\"Most viewed videos on YouTube from Wikipedia\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "58b23fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349e4171",
   "metadata": {},
   "source": [
    "Q2. Scrape the details team India’s international fixtures from bcci.tv. Url = https://www.bcci.tv/.                           \n",
    "You need to find following details:                                                                                             \n",
    "A) Match title (I.e. 1st ODI)                                                                                                  \n",
    "B) Series                                                                                                                      \n",
    "C) Place                                                                                                                       \n",
    "D) Date                                                                                                                        \n",
    "E) Time                                                                                                                        \n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code.                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5ccc5074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to driver\n",
    "driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "time.sleep(2)\n",
    "# opening site\n",
    "driver.get(\"https://www.bcci.tv/.\") \n",
    "# click on international \n",
    "driver.find_element(By.XPATH,'//a[@class=\"nav-link \"]').click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "49358dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on more\n",
    "driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div[3]/div[2]/div/button').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "736b2ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping urls of fixtures\n",
    "urls = []\n",
    "for i in driver.find_elements(By.XPATH,'//a[@class=\"match-center-btn ng-scope\"]'):\n",
    "    urls.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "269a7906",
   "metadata": {},
   "outputs": [],
   "source": [
    "Match_title = []\n",
    "Series = []\n",
    "Place = []\n",
    "Date = []\n",
    "Time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "94650c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Time\n",
    "try:\n",
    "    ti = driver.find_elements(By.XPATH,'//h5[@class=\"text-right ng-binding\"]')\n",
    "    for i in ti:\n",
    "        Time.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Time.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5e334f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    # scraping match title\n",
    "    try:\n",
    "        mat = driver.find_element(By.XPATH,'/html/body/div[2]/div/div[1]/div[3]/div[7]/div[3]/div/div[1]/div/div[1]/div[2]')\n",
    "        Match_title.append(mat.text)\n",
    "    except NoSuchElementException:\n",
    "        Match_title.append('-')\n",
    "    \n",
    "    # scraping series\n",
    "    try:\n",
    "        ser = driver.find_element(By.XPATH,'/html/body/div[2]/div/div[1]/div[3]/div[7]/div[3]/div/div[1]/div/div[1]/div[1]')\n",
    "        Series.append(ser.text)\n",
    "    except NoSuchElementException:\n",
    "        Series.append('-')        \n",
    "    \n",
    "    # scraping place\n",
    "    try:\n",
    "        pla = driver.find_element(By.XPATH,'//div[@class=\"matchVenue alignC\"]')\n",
    "        Place.append(pla.text)\n",
    "    except NoSuchElementException:\n",
    "        Place.append('-')   \n",
    "        \n",
    "    # scraping date\n",
    "    try:\n",
    "        da = driver.find_element(By.XPATH,'/html/body/div[2]/div/div[1]/div[3]/div[7]/div[3]/div/div[1]/div/div[2]/div[3]/div[2]')\n",
    "        Date.append(da.text)\n",
    "    except NoSuchElementException:\n",
    "        Date.append('-')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2881ba68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India’s international fixtures from bcci.tv.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match_title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st T20I</td>\n",
       "      <td>ASIA CUP WOMENS 2022</td>\n",
       "      <td>SYLHET OUTER CRICKET STADIUM ,  SYLHET</td>\n",
       "      <td>1 OCT 2022</td>\n",
       "      <td>1:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022-23</td>\n",
       "      <td>BARSAPARA CRICKET STADIUM ,  GUWAHATI</td>\n",
       "      <td>2 OCT 2022</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>ASIA CUP WOMENS 2022</td>\n",
       "      <td>SYLHET OUTER CRICKET STADIUM ,  SYLHET</td>\n",
       "      <td>3 OCT 2022</td>\n",
       "      <td>1:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>ASIA CUP WOMENS 2022</td>\n",
       "      <td>SYLHET OUTER CRICKET STADIUM ,  SYLHET</td>\n",
       "      <td>4 OCT 2022</td>\n",
       "      <td>1:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022-23</td>\n",
       "      <td>HOLKAR CRICKET STADIUM ,  INDORE</td>\n",
       "      <td>4 OCT 2022</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1st ODI</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA ODI SERIES 2022-23</td>\n",
       "      <td>BHARAT RATNA SHRI ATAL BIHARI VAJPAYEE EKANA C...</td>\n",
       "      <td>6 OCT 2022</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4th T20I</td>\n",
       "      <td>ASIA CUP WOMENS 2022</td>\n",
       "      <td>SYLHET INTERNATIONAL CRICKET STADIUM ,  SYLHET</td>\n",
       "      <td>7 OCT 2022</td>\n",
       "      <td>1:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5th T20I</td>\n",
       "      <td>ASIA CUP WOMENS 2022</td>\n",
       "      <td>SYLHET INTERNATIONAL CRICKET STADIUM ,  SYLHET</td>\n",
       "      <td>8 OCT 2022</td>\n",
       "      <td>1:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA ODI SERIES 2022-23</td>\n",
       "      <td>JSCA INTERNATIONAL STADIUM COMPLEX ,  RANCHI</td>\n",
       "      <td>9 OCT 2022</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6th T20I</td>\n",
       "      <td>ASIA CUP WOMENS 2022</td>\n",
       "      <td>SYLHET INTERNATIONAL CRICKET STADIUM ,  SYLHET</td>\n",
       "      <td>10 OCT 2022</td>\n",
       "      <td>1:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA ODI SERIES 2022-23</td>\n",
       "      <td>ARUN JAITLEY STADIUM ,  DELHI</td>\n",
       "      <td>11 OCT 2022</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Match_title                                         Series  \\\n",
       "1     1st T20I                           ASIA CUP WOMENS 2022   \n",
       "2     2nd T20I  SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022-23   \n",
       "3     2nd T20I                           ASIA CUP WOMENS 2022   \n",
       "4     3rd T20I                           ASIA CUP WOMENS 2022   \n",
       "5     3rd T20I  SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022-23   \n",
       "6      1st ODI  SOUTH AFRICA TOUR OF INDIA ODI SERIES 2022-23   \n",
       "7     4th T20I                           ASIA CUP WOMENS 2022   \n",
       "8     5th T20I                           ASIA CUP WOMENS 2022   \n",
       "9      2nd ODI  SOUTH AFRICA TOUR OF INDIA ODI SERIES 2022-23   \n",
       "10    6th T20I                           ASIA CUP WOMENS 2022   \n",
       "11     3rd ODI  SOUTH AFRICA TOUR OF INDIA ODI SERIES 2022-23   \n",
       "\n",
       "                                                Place         Date  \\\n",
       "1              SYLHET OUTER CRICKET STADIUM ,  SYLHET   1 OCT 2022   \n",
       "2               BARSAPARA CRICKET STADIUM ,  GUWAHATI   2 OCT 2022   \n",
       "3              SYLHET OUTER CRICKET STADIUM ,  SYLHET   3 OCT 2022   \n",
       "4              SYLHET OUTER CRICKET STADIUM ,  SYLHET   4 OCT 2022   \n",
       "5                    HOLKAR CRICKET STADIUM ,  INDORE   4 OCT 2022   \n",
       "6   BHARAT RATNA SHRI ATAL BIHARI VAJPAYEE EKANA C...   6 OCT 2022   \n",
       "7      SYLHET INTERNATIONAL CRICKET STADIUM ,  SYLHET   7 OCT 2022   \n",
       "8      SYLHET INTERNATIONAL CRICKET STADIUM ,  SYLHET   8 OCT 2022   \n",
       "9        JSCA INTERNATIONAL STADIUM COMPLEX ,  RANCHI   9 OCT 2022   \n",
       "10     SYLHET INTERNATIONAL CRICKET STADIUM ,  SYLHET  10 OCT 2022   \n",
       "11                      ARUN JAITLEY STADIUM ,  DELHI  11 OCT 2022   \n",
       "\n",
       "           Time  \n",
       "1   1:00 PM IST  \n",
       "2   7:00 PM IST  \n",
       "3   1:00 PM IST  \n",
       "4   1:00 PM IST  \n",
       "5   7:00 PM IST  \n",
       "6   1:30 PM IST  \n",
       "7   1:00 PM IST  \n",
       "8   1:00 PM IST  \n",
       "9   1:30 PM IST  \n",
       "10  1:00 PM IST  \n",
       "11  1:30 PM IST  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe to store data in tabular form\n",
    "df = pd.DataFrame({\"Match_title\":Match_title,\n",
    "                   \"Series\":Series,\n",
    "                   \"Place\":Place,\n",
    "                   \"Date\":Date,\n",
    "                   \"Time\":Time},index=list(range(1,len(Date)+1)))\n",
    "print(\"India’s international fixtures from bcci.tv.\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "86249eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# closing the driver\n",
    "driver.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c6f6e5",
   "metadata": {},
   "source": [
    "Q3. Scrape the details of selenium exception from guru99.com. Url = https://www.guru99.com/                                    \n",
    "You need to find following details:                                                                                            \n",
    "A) Name                                                                                                                        \n",
    "B) Description                                                                                                                 \n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code.                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd42ed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to driver\n",
    "driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "time.sleep(2)\n",
    "# opening site\n",
    "driver.get(\"https://www.guru99.com/\") \n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c79ecf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter selenium exception handling in search bar\n",
    "driver.find_element(By.XPATH,'//input[@class=\"gsc-input\"]').send_keys(\"selenium exception handling\")\n",
    "time.sleep(2)\n",
    "# click on go\n",
    "driver.find_element(By.XPATH,'//button[@class=\"gsc-search-button gsc-search-button-v2\"]').click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "beaf53a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on selenium exception handling\n",
    "driver.find_element(By.XPATH,'//a[@class=\"gs-title\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2202be03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shifting to next windows\n",
    "driver.switch_to.window(driver.window_handles[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d1698a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = [] # list for storing name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "cdce5913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Name of the exceptions\n",
    "for k in driver.find_elements(By.XPATH,'//p/strong')[1:42]:\n",
    "    name.append(k.text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "805c9f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = [] #list for storing description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8fc4c33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Description of exceptions\n",
    "for i in driver.find_elements(By.XPATH,'//p')[2:43]:\n",
    "    description.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c7e98abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of Exception</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1. ElementNotVisibleException:</td>\n",
       "      <td>1. ElementNotVisibleException: This type of Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2. ElementNotSelectableException:</td>\n",
       "      <td>2. ElementNotSelectableException: This Seleniu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3. NoSuchElementException:</td>\n",
       "      <td>3. NoSuchElementException: This Exception occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4. NoSuchFrameException:</td>\n",
       "      <td>4. NoSuchFrameException: This Exception occurs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5. NoAlertPresentException:</td>\n",
       "      <td>5. NoAlertPresentException: This Exception occ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6. NoSuchWindowException:</td>\n",
       "      <td>6. NoSuchWindowException: This Exception occur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7. StaleElementReferenceException:</td>\n",
       "      <td>7. StaleElementReferenceException: This Seleni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8. SessionNotFoundException:</td>\n",
       "      <td>8. SessionNotFoundException: The WebDriver is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9. TimeoutException:</td>\n",
       "      <td>9. TimeoutException: Thrown when there is not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10. WebDriverException:</td>\n",
       "      <td>10. WebDriverException: This Exception takes p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11. ConnectionClosedException:</td>\n",
       "      <td>11. ConnectionClosedException: This type of Ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12. ElementClickInterceptedException:</td>\n",
       "      <td>12. ElementClickInterceptedException: The comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13. ElementNotInteractableException:</td>\n",
       "      <td>13. ElementNotInteractableException: This Sele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14. ErrorInResponseException:</td>\n",
       "      <td>14. ErrorInResponseException: This happens whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15. ErrorHandler.UnknownServerException:</td>\n",
       "      <td>15. ErrorHandler.UnknownServerException: Excep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16. ImeActivationFailedException:</td>\n",
       "      <td>16. ImeActivationFailedException: This expecta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17. ImeNotAvailableException:</td>\n",
       "      <td>17. ImeNotAvailableException: It takes place w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18. InsecureCertificateException:</td>\n",
       "      <td>18. InsecureCertificateException: Navigation m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19. InvalidArgumentException:</td>\n",
       "      <td>19. InvalidArgumentException: It occurs when a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20. InvalidCookieDomainException:</td>\n",
       "      <td>20. InvalidCookieDomainException: This happens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21. InvalidCoordinatesException:</td>\n",
       "      <td>21. InvalidCoordinatesException: This type of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22. InvalidElementStateException:</td>\n",
       "      <td>22. InvalidElementStateException: It occurs wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23. InvalidSessionIdException:</td>\n",
       "      <td>23. InvalidSessionIdException: This Exception ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24. InvalidSwitchToTargetException:</td>\n",
       "      <td>24. InvalidSwitchToTargetException: This occur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25. JavascriptException:</td>\n",
       "      <td>25. JavascriptException: This issue occurs whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26. JsonException:</td>\n",
       "      <td>26. JsonException: It occurs when you afford t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27. NoSuchAttributeException:</td>\n",
       "      <td>27. NoSuchAttributeException: This kind of Exc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28. MoveTargetOutOfBoundsException:</td>\n",
       "      <td>28. MoveTargetOutOfBoundsException: It takes p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29. NoSuchContextException:</td>\n",
       "      <td>29. NoSuchContextException: ContextAware does ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30. NoSuchCookieException:</td>\n",
       "      <td>30. NoSuchCookieException: This Exception occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31. NotFoundException:</td>\n",
       "      <td>31. NotFoundException: This Exception is a sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32. RemoteDriverServerException:</td>\n",
       "      <td>32. RemoteDriverServerException: This Selenium...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33. ScreenshotException:</td>\n",
       "      <td>33. ScreenshotException: It is not possible to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34. SessionNotCreatedException:</td>\n",
       "      <td>34. SessionNotCreatedException: It happens whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35. UnableToSetCookieException:</td>\n",
       "      <td>35. UnableToSetCookieException: This occurs if...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36. UnexpectedTagNameException:</td>\n",
       "      <td>36. UnexpectedTagNameException: Happens if a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37. UnhandledAlertException:</td>\n",
       "      <td>37. UnhandledAlertException: This expectation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38. UnexpectedAlertPresentException:</td>\n",
       "      <td>38. UnexpectedAlertPresentException: It occurs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39. UnknownMethodException:</td>\n",
       "      <td>39. UnknownMethodException: This Exception hap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40. UnreachableBrowserException:</td>\n",
       "      <td>40. UnreachableBrowserException: This Exceptio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41. UnsupportedCommandException:</td>\n",
       "      <td>41. UnsupportedCommandException: This occurs w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name of Exception  \\\n",
       "1             1. ElementNotVisibleException:   \n",
       "2          2. ElementNotSelectableException:   \n",
       "3                 3. NoSuchElementException:   \n",
       "4                   4. NoSuchFrameException:   \n",
       "5                5. NoAlertPresentException:   \n",
       "6                  6. NoSuchWindowException:   \n",
       "7         7. StaleElementReferenceException:   \n",
       "8               8. SessionNotFoundException:   \n",
       "9                       9. TimeoutException:   \n",
       "10                   10. WebDriverException:   \n",
       "11            11. ConnectionClosedException:   \n",
       "12     12. ElementClickInterceptedException:   \n",
       "13      13. ElementNotInteractableException:   \n",
       "14             14. ErrorInResponseException:   \n",
       "15  15. ErrorHandler.UnknownServerException:   \n",
       "16         16. ImeActivationFailedException:   \n",
       "17             17. ImeNotAvailableException:   \n",
       "18         18. InsecureCertificateException:   \n",
       "19             19. InvalidArgumentException:   \n",
       "20         20. InvalidCookieDomainException:   \n",
       "21          21. InvalidCoordinatesException:   \n",
       "22         22. InvalidElementStateException:   \n",
       "23            23. InvalidSessionIdException:   \n",
       "24       24. InvalidSwitchToTargetException:   \n",
       "25                  25. JavascriptException:   \n",
       "26                        26. JsonException:   \n",
       "27             27. NoSuchAttributeException:   \n",
       "28       28. MoveTargetOutOfBoundsException:   \n",
       "29               29. NoSuchContextException:   \n",
       "30                30. NoSuchCookieException:   \n",
       "31                    31. NotFoundException:   \n",
       "32          32. RemoteDriverServerException:   \n",
       "33                  33. ScreenshotException:   \n",
       "34           34. SessionNotCreatedException:   \n",
       "35           35. UnableToSetCookieException:   \n",
       "36           36. UnexpectedTagNameException:   \n",
       "37              37. UnhandledAlertException:   \n",
       "38      38. UnexpectedAlertPresentException:   \n",
       "39               39. UnknownMethodException:   \n",
       "40          40. UnreachableBrowserException:   \n",
       "41          41. UnsupportedCommandException:   \n",
       "\n",
       "                                          Description  \n",
       "1   1. ElementNotVisibleException: This type of Se...  \n",
       "2   2. ElementNotSelectableException: This Seleniu...  \n",
       "3   3. NoSuchElementException: This Exception occu...  \n",
       "4   4. NoSuchFrameException: This Exception occurs...  \n",
       "5   5. NoAlertPresentException: This Exception occ...  \n",
       "6   6. NoSuchWindowException: This Exception occur...  \n",
       "7   7. StaleElementReferenceException: This Seleni...  \n",
       "8   8. SessionNotFoundException: The WebDriver is ...  \n",
       "9   9. TimeoutException: Thrown when there is not ...  \n",
       "10  10. WebDriverException: This Exception takes p...  \n",
       "11  11. ConnectionClosedException: This type of Ex...  \n",
       "12  12. ElementClickInterceptedException: The comm...  \n",
       "13  13. ElementNotInteractableException: This Sele...  \n",
       "14  14. ErrorInResponseException: This happens whi...  \n",
       "15  15. ErrorHandler.UnknownServerException: Excep...  \n",
       "16  16. ImeActivationFailedException: This expecta...  \n",
       "17  17. ImeNotAvailableException: It takes place w...  \n",
       "18  18. InsecureCertificateException: Navigation m...  \n",
       "19  19. InvalidArgumentException: It occurs when a...  \n",
       "20  20. InvalidCookieDomainException: This happens...  \n",
       "21  21. InvalidCoordinatesException: This type of ...  \n",
       "22  22. InvalidElementStateException: It occurs wh...  \n",
       "23  23. InvalidSessionIdException: This Exception ...  \n",
       "24  24. InvalidSwitchToTargetException: This occur...  \n",
       "25  25. JavascriptException: This issue occurs whi...  \n",
       "26  26. JsonException: It occurs when you afford t...  \n",
       "27  27. NoSuchAttributeException: This kind of Exc...  \n",
       "28  28. MoveTargetOutOfBoundsException: It takes p...  \n",
       "29  29. NoSuchContextException: ContextAware does ...  \n",
       "30  30. NoSuchCookieException: This Exception occu...  \n",
       "31  31. NotFoundException: This Exception is a sub...  \n",
       "32  32. RemoteDriverServerException: This Selenium...  \n",
       "33  33. ScreenshotException: It is not possible to...  \n",
       "34  34. SessionNotCreatedException: It happens whe...  \n",
       "35  35. UnableToSetCookieException: This occurs if...  \n",
       "36  36. UnexpectedTagNameException: Happens if a s...  \n",
       "37  37. UnhandledAlertException: This expectation ...  \n",
       "38  38. UnexpectedAlertPresentException: It occurs...  \n",
       "39  39. UnknownMethodException: This Exception hap...  \n",
       "40  40. UnreachableBrowserException: This Exceptio...  \n",
       "41  41. UnsupportedCommandException: This occurs w...  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe\n",
    "df = pd.DataFrame({\"Name of Exception\":name,\"Description\":description},index = list(range(1,len(name)+1)))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "753dec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5463dfb4",
   "metadata": {},
   "source": [
    "Q4. Scrape the details of State-wise GDP of India from statisticstime.com. Url = http://statisticstimes.com/                    \n",
    "You have to find following details:                                                                                            \n",
    "A) Rank                                                                                                                        \n",
    "B) State                                                                                                                       \n",
    "C) GSDP(18-19)                                                                                                                 \n",
    "D) GSDP(17-18)                                                                                                                 \n",
    "E) Share(2017)                                                                                                                 \n",
    "F) GDP($ billion)                                                                                                               \n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "b40083f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to driver\n",
    "driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "time.sleep(2)\n",
    "# opening site\n",
    "driver.get(\"http://statisticstimes.com/\") \n",
    "time.sleep(2)\n",
    "# click on economy\n",
    "driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/button').click()\n",
    "time.sleep(2)\n",
    "#click on india\n",
    "driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "87d40d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on india GDP\n",
    "driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "539fdcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping rank\n",
    "rank = []\n",
    "for i in driver.find_elements(By.XPATH,'//td[@class=\"data1\"]')[0:33]:\n",
    "    rank.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "be1132ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping states\n",
    "state = []\n",
    "for i in driver.find_elements(By.XPATH,'//td[@class=\"name\"]')[0:33]:\n",
    "    state.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "3926a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping GSDP (18-19)\n",
    "gsdp18_19 = []\n",
    "for i in driver.find_elements(By.XPATH,'//td[@class=\"data sorting_1\"]')[0:33]:\n",
    "    gsdp18_19.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "435d70cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping GSDP (19-20)\n",
    "gsdp19_20 = []\n",
    "for i in driver.find_elements(By.XPATH,'//td[@class=\"data\"]')[0::5][0:33]:\n",
    "    gsdp19_20.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "d9b59b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping share 2019\n",
    "share = []\n",
    "for i in driver.find_elements(By.XPATH,'//td[@class=\"data\"]')[1::5][0:33]:\n",
    "    share.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "9d266f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping GDP($ billion)\n",
    "GDP = []\n",
    "for i in driver.find_elements(By.XPATH,'//td[@class=\"data\"]')[2::5][0:33]:\n",
    "    GDP.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "548385ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indian states by GDP\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP (18-19)</th>\n",
       "      <th>GSDP (19-20)</th>\n",
       "      <th>Share (2019)</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>-</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>-</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>942,586</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>862,957</td>\n",
       "      <td>972,782</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>861,031</td>\n",
       "      <td>969,604</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>809,592</td>\n",
       "      <td>906,672</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>781,653</td>\n",
       "      <td>-</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>774,870</td>\n",
       "      <td>856,112</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>734,163</td>\n",
       "      <td>831,610</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>530,363</td>\n",
       "      <td>611,804</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>526,376</td>\n",
       "      <td>574,760</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>487,805</td>\n",
       "      <td>521,275</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>315,881</td>\n",
       "      <td>-</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>304,063</td>\n",
       "      <td>329,180</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>297,204</td>\n",
       "      <td>328,598</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>245,895</td>\n",
       "      <td>-</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>155,956</td>\n",
       "      <td>-</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>153,845</td>\n",
       "      <td>165,472</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>73,170</td>\n",
       "      <td>80,449</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>49,845</td>\n",
       "      <td>55,984</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>42,114</td>\n",
       "      <td>-</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>34,433</td>\n",
       "      <td>38,253</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>33,481</td>\n",
       "      <td>36,572</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>28,723</td>\n",
       "      <td>32,496</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>27,870</td>\n",
       "      <td>31,790</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>27,283</td>\n",
       "      <td>-</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>24,603</td>\n",
       "      <td>-</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>22,287</td>\n",
       "      <td>26,503</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP (18-19) GSDP (19-20) Share (2019)  \\\n",
       "1     1                Maharashtra    2,632,792            -       13.94%   \n",
       "2     2                 Tamil Nadu    1,630,208    1,845,853        8.63%   \n",
       "3     3              Uttar Pradesh    1,584,764    1,687,818        8.39%   \n",
       "4     4                    Gujarat    1,502,899            -        7.96%   \n",
       "5     5                  Karnataka    1,493,127    1,631,977        7.91%   \n",
       "6     6                West Bengal    1,089,898    1,253,832        5.77%   \n",
       "7     7                  Rajasthan      942,586    1,020,989        4.99%   \n",
       "8     8             Andhra Pradesh      862,957      972,782        4.57%   \n",
       "9     9                  Telangana      861,031      969,604        4.56%   \n",
       "10   10             Madhya Pradesh      809,592      906,672        4.29%   \n",
       "11   11                     Kerala      781,653            -        4.14%   \n",
       "12   12                      Delhi      774,870      856,112        4.10%   \n",
       "13   13                    Haryana      734,163      831,610        3.89%   \n",
       "14   14                      Bihar      530,363      611,804        2.81%   \n",
       "15   15                     Punjab      526,376      574,760        2.79%   \n",
       "16   16                     Odisha      487,805      521,275        2.58%   \n",
       "17   17                      Assam      315,881            -        1.67%   \n",
       "18   18               Chhattisgarh      304,063      329,180        1.61%   \n",
       "19   19                  Jharkhand      297,204      328,598        1.57%   \n",
       "20   20                Uttarakhand      245,895            -        1.30%   \n",
       "21   21            Jammu & Kashmir      155,956            -        0.83%   \n",
       "22   22           Himachal Pradesh      153,845      165,472        0.81%   \n",
       "23   23                        Goa       73,170       80,449        0.39%   \n",
       "24   24                    Tripura       49,845       55,984        0.26%   \n",
       "25   25                 Chandigarh       42,114            -        0.22%   \n",
       "26   26                 Puducherry       34,433       38,253        0.18%   \n",
       "27   27                  Meghalaya       33,481       36,572        0.18%   \n",
       "28   28                     Sikkim       28,723       32,496        0.15%   \n",
       "29   29                    Manipur       27,870       31,790        0.15%   \n",
       "30   30                   Nagaland       27,283            -        0.14%   \n",
       "31   31          Arunachal Pradesh       24,603            -        0.13%   \n",
       "32   32                    Mizoram       22,287       26,503        0.12%   \n",
       "33   33  Andaman & Nicobar Islands            -            -            -   \n",
       "\n",
       "   GDP($ billion)  \n",
       "1         399.921  \n",
       "2         247.629  \n",
       "3         240.726  \n",
       "4         228.290  \n",
       "5         226.806  \n",
       "6         165.556  \n",
       "7         143.179  \n",
       "8         131.083  \n",
       "9         130.791  \n",
       "10        122.977  \n",
       "11        118.733  \n",
       "12        117.703  \n",
       "13        111.519  \n",
       "14         80.562  \n",
       "15         79.957  \n",
       "16         74.098  \n",
       "17         47.982  \n",
       "18         46.187  \n",
       "19         45.145  \n",
       "20         37.351  \n",
       "21         23.690  \n",
       "22         23.369  \n",
       "23         11.115  \n",
       "24          7.571  \n",
       "25          6.397  \n",
       "26          5.230  \n",
       "27          5.086  \n",
       "28          4.363  \n",
       "29          4.233  \n",
       "30          4.144  \n",
       "31          3.737  \n",
       "32          3.385  \n",
       "33              -  "
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe\n",
    "df = pd.DataFrame({\"Rank\":rank,\"State\":state,\"GSDP (18-19)\":gsdp18_19,\"GSDP (19-20)\":gsdp19_20,\"Share (2019)\":share,\"GDP($ billion)\":GDP},index = list(range(1,len(GDP)+1)))\n",
    "print(\"Indian states by GDP\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "204a4d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28772b3",
   "metadata": {},
   "source": [
    "Q5. Scrape the details of trending repositories on Github.com. Url = https://github.com/                                        \n",
    "You have to find the following details:                                                                                         \n",
    "A) Repository title                                                                                                             \n",
    "B) Repository description                                                                                                       \n",
    "C) Contributors count                                                                                                           \n",
    "D) Language used                                                                                                               \n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "fb0c6342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to driver\n",
    "driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "time.sleep(2)\n",
    "# opening site\n",
    "driver.get(\"https://github.com/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "82a1b4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on open source\n",
    "driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[2]/div/nav/ul/li[3]/button').click()\n",
    "time.sleep(2)\n",
    "# click on trending\n",
    "driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/ul[3]/li[3]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "ca7d7a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping repo url\n",
    "url = []\n",
    "for i in driver.find_elements(By.XPATH,'//h1/a'):\n",
    "    url.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "6cb7576b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = []\n",
    "descp = []\n",
    "c_count = []\n",
    "lang = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "41571a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in url:\n",
    "    driver.get(u)\n",
    "    time.sleep(2)\n",
    "# scraping Repository title\n",
    "    try:\n",
    "        r = driver.find_element(By.XPATH,'//strong[@class=\"mr-2 flex-self-stretch\"]/a')      \n",
    "        rep.append(r.text)\n",
    "    except NoSuchElementException:\n",
    "        rep.append('-')    \n",
    "# extracting Repository description\n",
    "    try:\n",
    "        d = driver.find_element(By.XPATH,'/html/body/div[4]/div/main/turbo-frame/div/div/div/div[3]/div[2]/div/div[1]/div/p')\n",
    "        descp.append(d.text)\n",
    "    except NoSuchElementException:\n",
    "        descp.append('No descirption')\n",
    "# extracting Contributors count\n",
    "    try:\n",
    "        cc = driver.find_element(By.XPATH,'/html/body/div[4]/div/main/turbo-frame/div/div/div/div[3]/div[2]/div/div[5]/div/h2/a/span')\n",
    "        c_count.append(cc.text)\n",
    "    except NoSuchElementException:\n",
    "        try:\n",
    "            cc2 = driver.find_element(By.XPATH,'/html/body/div[4]/div/main/turbo-frame/div/div/div/div[3]/div[2]/div/div[4]/div/h2/a/span')\n",
    "            c_count.append(cc2.text)\n",
    "        except NoSuchElementException:\n",
    "            try:\n",
    "                cc3 = driver.find_element(By.XPATH,'/html/body/div[4]/div/main/turbo-frame/div/div/div/div[3]/div[2]/div/div[5]/div/h2/a/span')\n",
    "                c_count.append(cc3.text)\n",
    "            except NoSuchElementException:\n",
    "                c_count.append('1')\n",
    "# extracting langauges\n",
    "    try:\n",
    "        la = driver.find_element(By.XPATH,'/html/body/div[4]/div/main/turbo-frame/div/div/div/div[3]/div[2]/div/div[6]/div/ul/li[1]/a/span[1]')\n",
    "        lang.append(la.text)\n",
    "    except NoSuchElementException:\n",
    "        try:\n",
    "            la2 = driver.find_element(By.XPATH,'/html/body/div[4]/div/main/turbo-frame/div/div/div/div[3]/div[2]/div/div[5]/div/ul/li/a/span[1]')\n",
    "            lang.append(la2.text)\n",
    "        except NoSuchElementException:\n",
    "            lang.append('-')     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "81a3e337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trending repositories on Github\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>langauge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>workerd</td>\n",
       "      <td>The JavaScript / Wasm runtime that powers Clou...</td>\n",
       "      <td>30</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cypress</td>\n",
       "      <td>Fast, easy and reliable testing for anything t...</td>\n",
       "      <td>394</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cs-video-courses</td>\n",
       "      <td>List of Computer Science courses with video le...</td>\n",
       "      <td>69</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MOOS</td>\n",
       "      <td>C# x64 operating system programming with the ....</td>\n",
       "      <td>6</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Akebi-GC</td>\n",
       "      <td>Akebi Genshin Cheat for OS/CN 3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Freeze</td>\n",
       "      <td>Freeze is a payload toolkit for bypassing EDRs...</td>\n",
       "      <td>1</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MemoryPack</td>\n",
       "      <td>Zero encoding extreme performance binary seria...</td>\n",
       "      <td>5</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>Free Data Engineering course!</td>\n",
       "      <td>40</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>first-contributions</td>\n",
       "      <td>🚀✨ Help beginners to contribute to open source...</td>\n",
       "      <td>2,638</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sub</td>\n",
       "      <td>自用clash订阅链接</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>Tensors and Dynamic neural networks in Python ...</td>\n",
       "      <td>2,458</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>learn-cantrill-io-labs</td>\n",
       "      <td>Standard and Advanced Demos for learn.cantrill...</td>\n",
       "      <td>21</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>linkedin-skill-assessments-quizzes</td>\n",
       "      <td>Full reference of LinkedIn answers 2022 for sk...</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MaaAssistantArknights</td>\n",
       "      <td>《明日方舟》小助手，全日常一键长草！| An Arknights assistant com...</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>googletest</td>\n",
       "      <td>GoogleTest - Google Testing and Mocking Framework</td>\n",
       "      <td>369</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>system-design</td>\n",
       "      <td>Learn how to design systems at scale and prepa...</td>\n",
       "      <td>5</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>30-Days-Of-Python</td>\n",
       "      <td>30 days of Python programming challenge is a s...</td>\n",
       "      <td>7</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>beginners-typescript-tutorial</td>\n",
       "      <td>An interactive TypeScript tutorial for beginners</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Dreambooth-Stable-Diffusion</td>\n",
       "      <td>Implementation of Dreambooth (https://arxiv.or...</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>30-Days-Of-JavaScript</td>\n",
       "      <td>30 days of JavaScript programming challenge is...</td>\n",
       "      <td>31</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>stable-diffusion-webui</td>\n",
       "      <td>Stable Diffusion web UI</td>\n",
       "      <td>85</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>machine-learning-engineering-for-production-pu...</td>\n",
       "      <td>Public repo for DeepLearning.AI MLEP Specializ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>towhee</td>\n",
       "      <td>Towhee is a framework that is dedicated to mak...</td>\n",
       "      <td>29</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>FastjsonScan</td>\n",
       "      <td>Fastjson扫描器，可识别版本、依赖库、autoType状态等。A tool to di...</td>\n",
       "      <td>1</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>echarts</td>\n",
       "      <td>Apache ECharts is a powerful, interactive char...</td>\n",
       "      <td>176</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Repository title  \\\n",
       "1                                             workerd   \n",
       "2                                             cypress   \n",
       "3                                    cs-video-courses   \n",
       "4                                                MOOS   \n",
       "5                                            Akebi-GC   \n",
       "6                                              Freeze   \n",
       "7                                          MemoryPack   \n",
       "8                           data-engineering-zoomcamp   \n",
       "9                                 first-contributions   \n",
       "10                                                Sub   \n",
       "11                                            pytorch   \n",
       "12                             learn-cantrill-io-labs   \n",
       "13                 linkedin-skill-assessments-quizzes   \n",
       "14                              MaaAssistantArknights   \n",
       "15                                         googletest   \n",
       "16                                      system-design   \n",
       "17                                  30-Days-Of-Python   \n",
       "18                      beginners-typescript-tutorial   \n",
       "19                        Dreambooth-Stable-Diffusion   \n",
       "20                              30-Days-Of-JavaScript   \n",
       "21                             stable-diffusion-webui   \n",
       "22  machine-learning-engineering-for-production-pu...   \n",
       "23                                             towhee   \n",
       "24                                       FastjsonScan   \n",
       "25                                            echarts   \n",
       "\n",
       "                               Repository description Contributors count  \\\n",
       "1   The JavaScript / Wasm runtime that powers Clou...                 30   \n",
       "2   Fast, easy and reliable testing for anything t...                394   \n",
       "3   List of Computer Science courses with video le...                 69   \n",
       "4   C# x64 operating system programming with the ....                  6   \n",
       "5                   Akebi Genshin Cheat for OS/CN 3.0                  1   \n",
       "6   Freeze is a payload toolkit for bypassing EDRs...                  1   \n",
       "7   Zero encoding extreme performance binary seria...                  5   \n",
       "8                       Free Data Engineering course!                 40   \n",
       "9   🚀✨ Help beginners to contribute to open source...              2,638   \n",
       "10                                        自用clash订阅链接                  1   \n",
       "11  Tensors and Dynamic neural networks in Python ...              2,458   \n",
       "12  Standard and Advanced Demos for learn.cantrill...                 21   \n",
       "13  Full reference of LinkedIn answers 2022 for sk...                      \n",
       "14  《明日方舟》小助手，全日常一键长草！| An Arknights assistant com...                  1   \n",
       "15  GoogleTest - Google Testing and Mocking Framework                369   \n",
       "16  Learn how to design systems at scale and prepa...                  5   \n",
       "17  30 days of Python programming challenge is a s...                  7   \n",
       "18   An interactive TypeScript tutorial for beginners                  1   \n",
       "19  Implementation of Dreambooth (https://arxiv.or...                  1   \n",
       "20  30 days of JavaScript programming challenge is...                 31   \n",
       "21                            Stable Diffusion web UI                 85   \n",
       "22  Public repo for DeepLearning.AI MLEP Specializ...                  3   \n",
       "23  Towhee is a framework that is dedicated to mak...                 29   \n",
       "24  Fastjson扫描器，可识别版本、依赖库、autoType状态等。A tool to di...                  1   \n",
       "25  Apache ECharts is a powerful, interactive char...                176   \n",
       "\n",
       "            langauge  \n",
       "1                C++  \n",
       "2         JavaScript  \n",
       "3                  -  \n",
       "4                 C#  \n",
       "5                  -  \n",
       "6                 Go  \n",
       "7                 C#  \n",
       "8   Jupyter Notebook  \n",
       "9                  -  \n",
       "10                 -  \n",
       "11               C++  \n",
       "12            Python  \n",
       "13                 -  \n",
       "14                 -  \n",
       "15               C++  \n",
       "16                 -  \n",
       "17            Python  \n",
       "18                 -  \n",
       "19                 -  \n",
       "20        JavaScript  \n",
       "21            Python  \n",
       "22  Jupyter Notebook  \n",
       "23            Python  \n",
       "24                Go  \n",
       "25        TypeScript  "
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe\n",
    "df = pd.DataFrame({\"Repository title\":rep,\"Repository description\":descp,\"Contributors count\":c_count,\"langauge\":lang},index=list(range(1,len(lang)+1)))\n",
    "print(\"trending repositories on Github\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "50360ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abde8208",
   "metadata": {},
   "source": [
    "Q6. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/                                     \n",
    "You have to find the following details:                                                                                        \n",
    "A) Song name                                                                                                                   \n",
    "B) Artist name                                                                                                                \n",
    "C) Last week rank                                                                                                              \n",
    "D) Peak rank                                                                                                                   \n",
    "E) Weeks on board                                                                                                             \n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "3dd2808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to driver\n",
    "driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "time.sleep(2)\n",
    "# opening site\n",
    "driver.get(\"https:/www.billboard.com/\") \n",
    "time.sleep(2)\n",
    "# click on hot 100\n",
    "driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[3]/div/nav/ul/li[1]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "8040b7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list to store data\n",
    "song = []\n",
    "artist = []\n",
    "rank = []\n",
    "la_we_rank = []\n",
    "pe_rank = []\n",
    "we_on_bord = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "8795740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping song name\n",
    "for i  in driver.find_elements(By.XPATH,'//h3'):\n",
    "    song.append(i.text)\n",
    "song = song[7::4][0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "5d8c45b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping 1st artist name\n",
    "ar1=driver.find_element(By.XPATH,'//span[@class=\"c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only u-font-size-20@tablet\"]')\n",
    "artist.append(ar1.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "0f42221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping all other artist name\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only\"]'):\n",
    "    artist.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "f1306f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping last weak rank\n",
    "# all  other\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-font-primary-m lrv-u-padding-tb-050@mobile-max\"]'):\n",
    "    rank.append(i.text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "48a6e2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st\n",
    "la=driver.find_element(By.XPATH,'//span[@class=\"c-label  a-font-primary-bold-l a-font-primary-m@mobile-max u-font-weight-normal@mobile-max lrv-u-padding-tb-050@mobile-max u-font-size-32@tablet\"]')\n",
    "la_we_rank.append(la.text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "024b2415",
   "metadata": {},
   "outputs": [],
   "source": [
    "la_we_rank = la_we_rank+rank[0::6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "a47798d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peak rank\n",
    "pr=driver.find_element(By.XPATH,'/html/body/div[3]/main/div[2]/div[3]/div/div/div/div[2]/div[2]/ul/li[4]/ul/li[5]/span')\n",
    "pe_rank.append(pr.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "80d06e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe_rank = pe_rank + rank[1::6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "88932df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Weeks on board\n",
    "wb=driver.find_element(By.XPATH,'/html/body/div[3]/main/div[2]/div[3]/div/div/div/div[2]/div[2]/ul/li[4]/ul/li[6]/span')\n",
    "we_on_bord.append(wb.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "ec9372ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "we_on_bord = we_on_bord + rank[2::6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "6199f10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 100 songs on billiboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Last week rank</th>\n",
       "      <th>Peak rank</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As It Was</td>\n",
       "      <td>Harry Styles</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bad Habit</td>\n",
       "      <td>Steve Lacy</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I Like You (A Happier Song)</td>\n",
       "      <td>Post Malone Featuring Doja Cat</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sunroof</td>\n",
       "      <td>Nicky Youre &amp; dazy</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Super Freaky Girl</td>\n",
       "      <td>Nicki Minaj</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Thought You Should Know</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>98</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Where It Ends</td>\n",
       "      <td>Bailey Zimmerman</td>\n",
       "      <td>93</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Backstage Passes</td>\n",
       "      <td>EST Gee Featuring Jack Harlow</td>\n",
       "      <td>-</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Snap</td>\n",
       "      <td>Rosa Linn</td>\n",
       "      <td>97</td>\n",
       "      <td>93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Beat The Odds</td>\n",
       "      <td>Lil Tjay</td>\n",
       "      <td>91</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Song name                          Artist  \\\n",
       "1                      As It Was                    Harry Styles   \n",
       "2                      Bad Habit                      Steve Lacy   \n",
       "3    I Like You (A Happier Song)  Post Malone Featuring Doja Cat   \n",
       "4                        Sunroof              Nicky Youre & dazy   \n",
       "5              Super Freaky Girl                     Nicki Minaj   \n",
       "..                           ...                             ...   \n",
       "96       Thought You Should Know                   Morgan Wallen   \n",
       "97                 Where It Ends                Bailey Zimmerman   \n",
       "98              Backstage Passes   EST Gee Featuring Jack Harlow   \n",
       "99                          Snap                       Rosa Linn   \n",
       "100                Beat The Odds                        Lil Tjay   \n",
       "\n",
       "    Last week rank Peak rank Weeks on board  \n",
       "1                1         1             25  \n",
       "2                2         2             12  \n",
       "3                5         3             16  \n",
       "4                4         4             17  \n",
       "5                3         1              6  \n",
       "..             ...       ...            ...  \n",
       "96              98        12             20  \n",
       "97              93        32              5  \n",
       "98               -        98              1  \n",
       "99              97        93              4  \n",
       "100             91        36              4  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe\n",
    "df = pd.DataFrame({'Song name':song,'Artist':artist,'Last week rank':la_we_rank,'Peak rank':pe_rank,'Weeks on board':we_on_bord},index=list(range(1,len(song)+1)))\n",
    "print(\"top 100 songs on billiboard\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "fc1c3c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890ccae5",
   "metadata": {},
   "source": [
    "Q7. Scrape the details of Data science recruiters from naukri.com. Url = https://www.naukri.com/                                \n",
    "You have to find the following details:                                                                                       \n",
    "A) Name                                                                                                                      \n",
    "B) Designation                                                                                                                \n",
    "C) Company                                                                                                                  \n",
    "D) Skills they hire for                                                                                                       \n",
    "E) Location                                                                                                                 \n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and click on   search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "01845ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to driver\n",
    "driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "time.sleep(2)\n",
    "# opening site\n",
    "driver.get(\"https://www.naukri.com/naukri-dot-com-recruiters\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "4881bf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter data science in search bar\n",
    "driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/div/form/div[1]/div/div[1]/div[1]/div[2]/input').clear()\n",
    "time.sleep(1)\n",
    "driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/div/form/div[1]/div/div[1]/div[1]/div[2]/input').send_keys(\"Data Science\")\n",
    "time.sleep(1)\n",
    "# click search\n",
    "driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/div/form/div[1]/button').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "6fc7be57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping urls of recruiter\n",
    "url = []\n",
    "for i in driver.find_elements(By.XPATH,'//a[@class=\"ellipsis\"]'):\n",
    "    url.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "e0b65e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=url[0::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "9afbd756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list\n",
    "Name = []\n",
    "Designation = []\n",
    "Company = []\n",
    "Skills_they_hire_for = []\n",
    "Location = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "e6da3aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in url:\n",
    "    driver.get(u)\n",
    "    time.sleep(1)\n",
    "# Extracting Name \n",
    "    try:\n",
    "        n = driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[1]/div[2]/div[2]/h1')      \n",
    "        Name.append(n.text)\n",
    "    except NoSuchElementException:\n",
    "        Name.append('-')    \n",
    "# extracting Designation\n",
    "    try:\n",
    "        d = driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[1]/div[2]/div[3]')\n",
    "        Designation.append(d.text)\n",
    "    except NoSuchElementException:\n",
    "        Designation.append('-')\n",
    "# extracting Company\n",
    "    try:\n",
    "        c = driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/div[2]/p[1]')\n",
    "        Company.append(c.text)\n",
    "    except NoSuchElementException:\n",
    "        Company.append('-')  \n",
    "# extracting Skills_they_hire_for\n",
    "    try:\n",
    "        sk = driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/div[1]/p[1]')\n",
    "        Skills_they_hire_for.append(sk.text)\n",
    "    except NoSuchElementException:\n",
    "        Skills_they_hire_for.append('-') \n",
    "# extracting Location\n",
    "    try:\n",
    "        lo = driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[1]/div[2]/div[5]/a')\n",
    "        Location.append(lo.text)\n",
    "    except NoSuchElementException:\n",
    "        Location.append('-')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "3f6dfc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "details of Data science recruiters from naukri\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Skills_they_hire_for</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>Classic ASP Developer , Internet Marketing Pro...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Shore Infotech India Pvt. Ltd (Since Dec-2016)</td>\n",
       "      <td>.Net , Java , Data Science , Linux Administrat...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MARSIAN Technologies LLP (Since Feb-2016)</td>\n",
       "      <td>Mid Level, Junior Level</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Enerlytics Software Solutions Pvt Ltd</td>\n",
       "      <td>, Mean Stack , javascript , angularjs , mongod...</td>\n",
       "      <td>Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>subhas patel</td>\n",
       "      <td>Founder &amp; CEO</td>\n",
       "      <td>LibraryXProject</td>\n",
       "      <td>Hadoop , Spark , Digital Strategy , Data Archi...</td>\n",
       "      <td>UK - (london)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Abhishek - Only Analytics Hiring - India and APAC</td>\n",
       "      <td>Recruitment - Lead Consultant</td>\n",
       "      <td>Apidel Technologies Division of Transpower (Si...</td>\n",
       "      <td>Analytics , Business Intelligence , Business A...</td>\n",
       "      <td>Vadodara / Baroda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Institute for Financial Management and Research</td>\n",
       "      <td>Programme Manager</td>\n",
       "      <td>IFMR (Since May-2017)</td>\n",
       "      <td>Analytics &amp; Business Intelligence</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Balu Ramesh</td>\n",
       "      <td>HR Administrator</td>\n",
       "      <td>Techvantage Systems Pvt Ltd (Since Dec-2014)</td>\n",
       "      <td>Machine Learning , algorithms , Go Getter , Co...</td>\n",
       "      <td>Trivandrum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Asif Lucknowi</td>\n",
       "      <td>Director</td>\n",
       "      <td>-</td>\n",
       "      <td>Weupskill- Live Wire India</td>\n",
       "      <td>Indore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>InstaFinancials</td>\n",
       "      <td>Human Resource</td>\n",
       "      <td>CBL Data Science Private Limited</td>\n",
       "      <td>Junior Level, Mid Level</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Priyanka Akiri</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Infinitive Software Solutions</td>\n",
       "      <td>Mid Level, High Level</td>\n",
       "      <td>Hyderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Kalpana Dumpala</td>\n",
       "      <td>Executive Hiring</td>\n",
       "      <td>Innominds Software (Since Feb-2015)</td>\n",
       "      <td>Qa , Ui , ux , Java Developer , Java Architect...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mubarak</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>-</td>\n",
       "      <td>MoneyTap</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Kushal Rastogi</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>-</td>\n",
       "      <td>QuantMagnum Technologies Pvt. Ltd.</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Vaishnavi Kudalkar</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Codeachive learning</td>\n",
       "      <td>Junior Level, Mid Level</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kapil Devang</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>BISP Solutions</td>\n",
       "      <td>Big Data , Hadoop , Data Analytics , Data Science</td>\n",
       "      <td>Bhopal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Mahesh Babu Channa</td>\n",
       "      <td>HR Team Lead</td>\n",
       "      <td>SocialPrachar.com (Since Jan-2014)</td>\n",
       "      <td>Junior Level, Mid Level</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sakshi Chhikara</td>\n",
       "      <td>Assistant Manager HR</td>\n",
       "      <td>BIZ INFOTECNO PRIVATE LIMITED (Since Oct-2020)</td>\n",
       "      <td>High Level</td>\n",
       "      <td>Chandigarh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Ruchi Dhote</td>\n",
       "      <td>Senior Executive Talent Acquisition</td>\n",
       "      <td>Bristlecone India Ltd (Since Apr-2021)</td>\n",
       "      <td>IT Skills</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Manisha Yadav</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Easi Tax</td>\n",
       "      <td>Mid Level</td>\n",
       "      <td>Navi Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Riya Rajesh</td>\n",
       "      <td>Manager Talent Acquisition</td>\n",
       "      <td>Novelworx Digital Solutions (Since May-2019)</td>\n",
       "      <td>IT-Software/Software Services</td>\n",
       "      <td>Cochin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Rashmi Bhattacharjee</td>\n",
       "      <td>HR Head</td>\n",
       "      <td>AXESTRACK SOFTWARE SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>Mid Level, Top Mangement Level</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Faizan Kareem</td>\n",
       "      <td>HR MANAGER</td>\n",
       "      <td>FirstTech Consaltants Pvt.Ltd</td>\n",
       "      <td>Data Analytics , Data Science , Machine Learni...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Rithika dadwal</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Affine Analytics</td>\n",
       "      <td>Junior Level, Mid Level</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Sandhya Khandagale</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Compumatrice Multimedia Pvt Ltd</td>\n",
       "      <td>High Level, Mid Level</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Shaun Rao</td>\n",
       "      <td>Manager - Human Resources</td>\n",
       "      <td>Exela Technologies (Since Nov-2014)</td>\n",
       "      <td>Java , Net , Angularjs , Hr , Infrastructure ,...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Azahar Shaikh</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>NEAL ANALYTICS SERVICES PVT LTD</td>\n",
       "      <td>Mid Level, High Level</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Manas</td>\n",
       "      <td>Lead Talent acquisition</td>\n",
       "      <td>Autumn Leaf Consulting Services Private Limited</td>\n",
       "      <td>High Level, Top Mangement Level</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>kumar</td>\n",
       "      <td>Proprietor</td>\n",
       "      <td>trainin</td>\n",
       "      <td>Data Science , Hadoop , Rpas , Devops , Python...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Sunil Vedula</td>\n",
       "      <td>CEO</td>\n",
       "      <td>Nanoprecise Sci Corp</td>\n",
       "      <td>Signal Processing , Machine Learning , Neural ...</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Rajat Kumar</td>\n",
       "      <td>Founder &amp; CEO</td>\n",
       "      <td>R.S Consultancy &amp; Services</td>\n",
       "      <td>Web Technologies , Project Management , Softwa...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Dhruv Dev Dubey</td>\n",
       "      <td>Company Recruitment Head</td>\n",
       "      <td>Confidential (Since Jun-2016)</td>\n",
       "      <td>S. Finance Manager , Freshers , Experience , S...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Jayanth N</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>Dollarbird Information Services Pvt, Ltd (Sinc...</td>\n",
       "      <td>Data Analytics , Managed Services , Team Leading</td>\n",
       "      <td>Mysoru / Mysore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Avodha</td>\n",
       "      <td>Business Development Associate</td>\n",
       "      <td>-</td>\n",
       "      <td>Nikitha Palaparthi</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SREEDHAR</td>\n",
       "      <td>Recruitment Consultant</td>\n",
       "      <td>-</td>\n",
       "      <td>JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Priya Khare</td>\n",
       "      <td>Senior Manager</td>\n",
       "      <td>-</td>\n",
       "      <td>Independent Consultant</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Amit Sharma</td>\n",
       "      <td>Consultant</td>\n",
       "      <td>-</td>\n",
       "      <td>ASCO consulting</td>\n",
       "      <td>New Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Kanan</td>\n",
       "      <td>senior technology instructor</td>\n",
       "      <td>NY INST</td>\n",
       "      <td>Mid Level, Junior Level</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Shashikant Chaudhary</td>\n",
       "      <td>HR Recruiter/HR Excutive</td>\n",
       "      <td>-</td>\n",
       "      <td>3D India Staffing Research &amp; Consulting Co. India</td>\n",
       "      <td>Aligarh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Brad</td>\n",
       "      <td>Manager, Technical Recruiting</td>\n",
       "      <td>O.C. Tanner (Since Jan-2019)</td>\n",
       "      <td>Junior Level, High Level</td>\n",
       "      <td>Salt Lake City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Rutuja Pawar</td>\n",
       "      <td>Technical Recruiter</td>\n",
       "      <td>Demand Matrix (Since Feb-2018)</td>\n",
       "      <td>Python , Php , Qa Automation , Ui , Wordpre</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Madhusudhan Sridhar</td>\n",
       "      <td>Erp Implementer</td>\n",
       "      <td>-</td>\n",
       "      <td>MADHUSUDHAN SRIDHAR</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Ankit Sinha</td>\n",
       "      <td>Head-Analytics</td>\n",
       "      <td>-</td>\n",
       "      <td>Suntech Global (Since Feb-2018)</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Gaurav Chouhan</td>\n",
       "      <td>Chief Technical Officer</td>\n",
       "      <td>Strategic Consulting Lab</td>\n",
       "      <td>Top Mangement Level, Junior Level</td>\n",
       "      <td>Indore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Rashi Kacker</td>\n",
       "      <td>Sr Product Manager</td>\n",
       "      <td>Impel Labs Pvt. Ltd.</td>\n",
       "      <td>Data Science , Node.js , Angularjs</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Ashwini</td>\n",
       "      <td>Director, Global Delivery</td>\n",
       "      <td>-</td>\n",
       "      <td>MRP Advisers (Since Oct-2017)</td>\n",
       "      <td>MYSORE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Balaji Kolli</td>\n",
       "      <td>Co-Founder</td>\n",
       "      <td>-</td>\n",
       "      <td>Saras Solutions India Pvt Ltd</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Rajani Nagaraj</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>WildJasmine</td>\n",
       "      <td>java , hadoop , r , Machine Learning , spark ,...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ROHIT Kumar</td>\n",
       "      <td>Architect</td>\n",
       "      <td>LNT Private Limited (Since Jul-2017)</td>\n",
       "      <td>Mid Level, High Level</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Amir Chowdhury</td>\n",
       "      <td>Managing Partner</td>\n",
       "      <td>-</td>\n",
       "      <td>Granular.ai</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name  \\\n",
       "1                                        Aakash Harit   \n",
       "2                                shravan Kumar Gaddam   \n",
       "3                            MARSIAN Technologies LLP   \n",
       "4                                        Anik Agrawal   \n",
       "5                                        subhas patel   \n",
       "6   Abhishek - Only Analytics Hiring - India and APAC   \n",
       "7     Institute for Financial Management and Research   \n",
       "8                                         Balu Ramesh   \n",
       "9                                       Asif Lucknowi   \n",
       "10                                    InstaFinancials   \n",
       "11                                     Priyanka Akiri   \n",
       "12                                    Kalpana Dumpala   \n",
       "13                                            Mubarak   \n",
       "14                                     Kushal Rastogi   \n",
       "15                                 Vaishnavi Kudalkar   \n",
       "16                                       Kapil Devang   \n",
       "17                                 Mahesh Babu Channa   \n",
       "18                                    Sakshi Chhikara   \n",
       "19                                        Ruchi Dhote   \n",
       "20                                      Manisha Yadav   \n",
       "21                                        Riya Rajesh   \n",
       "22                               Rashmi Bhattacharjee   \n",
       "23                                      Faizan Kareem   \n",
       "24                                     Rithika dadwal   \n",
       "25                                 Sandhya Khandagale   \n",
       "26                                          Shaun Rao   \n",
       "27                                      Azahar Shaikh   \n",
       "28                                              Manas   \n",
       "29                                              kumar   \n",
       "30                                       Sunil Vedula   \n",
       "31                                        Rajat Kumar   \n",
       "32                                    Dhruv Dev Dubey   \n",
       "33                                          Jayanth N   \n",
       "34                                             Avodha   \n",
       "35                                           SREEDHAR   \n",
       "36                                        Priya Khare   \n",
       "37                                        Amit Sharma   \n",
       "38                                              Kanan   \n",
       "39                               Shashikant Chaudhary   \n",
       "40                                               Brad   \n",
       "41                                       Rutuja Pawar   \n",
       "42                                Madhusudhan Sridhar   \n",
       "43                                        Ankit Sinha   \n",
       "44                                     Gaurav Chouhan   \n",
       "45                                       Rashi Kacker   \n",
       "46                                            Ashwini   \n",
       "47                                       Balaji Kolli   \n",
       "48                                     Rajani Nagaraj   \n",
       "49                                        ROHIT Kumar   \n",
       "50                                     Amir Chowdhury   \n",
       "\n",
       "                            Designation  \\\n",
       "1                            HR Manager   \n",
       "2                     Company Recruiter   \n",
       "3                            Company HR   \n",
       "4                     Company Recruiter   \n",
       "5                         Founder & CEO   \n",
       "6         Recruitment - Lead Consultant   \n",
       "7                     Programme Manager   \n",
       "8                      HR Administrator   \n",
       "9                              Director   \n",
       "10                       Human Resource   \n",
       "11                           HR Manager   \n",
       "12                     Executive Hiring   \n",
       "13                           Company HR   \n",
       "14                           Company HR   \n",
       "15                         HR Executive   \n",
       "16                           HR Manager   \n",
       "17                         HR Team Lead   \n",
       "18                 Assistant Manager HR   \n",
       "19  Senior Executive Talent Acquisition   \n",
       "20                         HR Executive   \n",
       "21           Manager Talent Acquisition   \n",
       "22                              HR Head   \n",
       "23                           HR MANAGER   \n",
       "24                         HR Recruiter   \n",
       "25                         HR Recruiter   \n",
       "26            Manager - Human Resources   \n",
       "27                    Company Recruiter   \n",
       "28              Lead Talent acquisition   \n",
       "29                           Proprietor   \n",
       "30                                  CEO   \n",
       "31                        Founder & CEO   \n",
       "32             Company Recruitment Head   \n",
       "33                      Project Manager   \n",
       "34       Business Development Associate   \n",
       "35               Recruitment Consultant   \n",
       "36                       Senior Manager   \n",
       "37                           Consultant   \n",
       "38         senior technology instructor   \n",
       "39             HR Recruiter/HR Excutive   \n",
       "40        Manager, Technical Recruiting   \n",
       "41                  Technical Recruiter   \n",
       "42                      Erp Implementer   \n",
       "43                       Head-Analytics   \n",
       "44              Chief Technical Officer   \n",
       "45                   Sr Product Manager   \n",
       "46            Director, Global Delivery   \n",
       "47                           Co-Founder   \n",
       "48                           HR Manager   \n",
       "49                            Architect   \n",
       "50                     Managing Partner   \n",
       "\n",
       "                                              Company  \\\n",
       "1                                Data Science Network   \n",
       "2      Shore Infotech India Pvt. Ltd (Since Dec-2016)   \n",
       "3           MARSIAN Technologies LLP (Since Feb-2016)   \n",
       "4               Enerlytics Software Solutions Pvt Ltd   \n",
       "5                                     LibraryXProject   \n",
       "6   Apidel Technologies Division of Transpower (Si...   \n",
       "7                               IFMR (Since May-2017)   \n",
       "8        Techvantage Systems Pvt Ltd (Since Dec-2014)   \n",
       "9                                                   -   \n",
       "10                   CBL Data Science Private Limited   \n",
       "11                      Infinitive Software Solutions   \n",
       "12                Innominds Software (Since Feb-2015)   \n",
       "13                                                  -   \n",
       "14                                                  -   \n",
       "15                                Codeachive learning   \n",
       "16                                     BISP Solutions   \n",
       "17                 SocialPrachar.com (Since Jan-2014)   \n",
       "18     BIZ INFOTECNO PRIVATE LIMITED (Since Oct-2020)   \n",
       "19             Bristlecone India Ltd (Since Apr-2021)   \n",
       "20                                           Easi Tax   \n",
       "21       Novelworx Digital Solutions (Since May-2019)   \n",
       "22       AXESTRACK SOFTWARE SOLUTIONS PRIVATE LIMITED   \n",
       "23                      FirstTech Consaltants Pvt.Ltd   \n",
       "24                                   Affine Analytics   \n",
       "25                    Compumatrice Multimedia Pvt Ltd   \n",
       "26                Exela Technologies (Since Nov-2014)   \n",
       "27                    NEAL ANALYTICS SERVICES PVT LTD   \n",
       "28    Autumn Leaf Consulting Services Private Limited   \n",
       "29                                            trainin   \n",
       "30                               Nanoprecise Sci Corp   \n",
       "31                         R.S Consultancy & Services   \n",
       "32                      Confidential (Since Jun-2016)   \n",
       "33  Dollarbird Information Services Pvt, Ltd (Sinc...   \n",
       "34                                                  -   \n",
       "35                                                  -   \n",
       "36                                                  -   \n",
       "37                                                  -   \n",
       "38                                            NY INST   \n",
       "39                                                  -   \n",
       "40                       O.C. Tanner (Since Jan-2019)   \n",
       "41                     Demand Matrix (Since Feb-2018)   \n",
       "42                                                  -   \n",
       "43                                                  -   \n",
       "44                           Strategic Consulting Lab   \n",
       "45                               Impel Labs Pvt. Ltd.   \n",
       "46                                                  -   \n",
       "47                                                  -   \n",
       "48                                        WildJasmine   \n",
       "49               LNT Private Limited (Since Jul-2017)   \n",
       "50                                                  -   \n",
       "\n",
       "                                 Skills_they_hire_for  \\\n",
       "1   Classic ASP Developer , Internet Marketing Pro...   \n",
       "2   .Net , Java , Data Science , Linux Administrat...   \n",
       "3                             Mid Level, Junior Level   \n",
       "4   , Mean Stack , javascript , angularjs , mongod...   \n",
       "5   Hadoop , Spark , Digital Strategy , Data Archi...   \n",
       "6   Analytics , Business Intelligence , Business A...   \n",
       "7                   Analytics & Business Intelligence   \n",
       "8   Machine Learning , algorithms , Go Getter , Co...   \n",
       "9                          Weupskill- Live Wire India   \n",
       "10                            Junior Level, Mid Level   \n",
       "11                              Mid Level, High Level   \n",
       "12  Qa , Ui , ux , Java Developer , Java Architect...   \n",
       "13                                           MoneyTap   \n",
       "14                 QuantMagnum Technologies Pvt. Ltd.   \n",
       "15                            Junior Level, Mid Level   \n",
       "16  Big Data , Hadoop , Data Analytics , Data Science   \n",
       "17                            Junior Level, Mid Level   \n",
       "18                                         High Level   \n",
       "19                                          IT Skills   \n",
       "20                                          Mid Level   \n",
       "21                      IT-Software/Software Services   \n",
       "22                     Mid Level, Top Mangement Level   \n",
       "23  Data Analytics , Data Science , Machine Learni...   \n",
       "24                            Junior Level, Mid Level   \n",
       "25                              High Level, Mid Level   \n",
       "26  Java , Net , Angularjs , Hr , Infrastructure ,...   \n",
       "27                              Mid Level, High Level   \n",
       "28                    High Level, Top Mangement Level   \n",
       "29  Data Science , Hadoop , Rpas , Devops , Python...   \n",
       "30  Signal Processing , Machine Learning , Neural ...   \n",
       "31  Web Technologies , Project Management , Softwa...   \n",
       "32  S. Finance Manager , Freshers , Experience , S...   \n",
       "33   Data Analytics , Managed Services , Team Leading   \n",
       "34                                 Nikitha Palaparthi   \n",
       "35        JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED   \n",
       "36                             Independent Consultant   \n",
       "37                                    ASCO consulting   \n",
       "38                            Mid Level, Junior Level   \n",
       "39  3D India Staffing Research & Consulting Co. India   \n",
       "40                           Junior Level, High Level   \n",
       "41        Python , Php , Qa Automation , Ui , Wordpre   \n",
       "42                                MADHUSUDHAN SRIDHAR   \n",
       "43                    Suntech Global (Since Feb-2018)   \n",
       "44                  Top Mangement Level, Junior Level   \n",
       "45                 Data Science , Node.js , Angularjs   \n",
       "46                      MRP Advisers (Since Oct-2017)   \n",
       "47                      Saras Solutions India Pvt Ltd   \n",
       "48  java , hadoop , r , Machine Learning , spark ,...   \n",
       "49                              Mid Level, High Level   \n",
       "50                                        Granular.ai   \n",
       "\n",
       "                    Location  \n",
       "1                      Delhi  \n",
       "2   Hyderabad / Secunderabad  \n",
       "3                       Pune  \n",
       "4                  Ahmedabad  \n",
       "5              UK - (london)  \n",
       "6          Vadodara / Baroda  \n",
       "7                    Chennai  \n",
       "8                 Trivandrum  \n",
       "9                     Indore  \n",
       "10     Bengaluru / Bangalore  \n",
       "11                 Hyderabad  \n",
       "12  Hyderabad / Secunderabad  \n",
       "13     Bengaluru / Bangalore  \n",
       "14                    Mumbai  \n",
       "15                    Mumbai  \n",
       "16                    Bhopal  \n",
       "17  Hyderabad / Secunderabad  \n",
       "18                Chandigarh  \n",
       "19                      Pune  \n",
       "20               Navi Mumbai  \n",
       "21                    Cochin  \n",
       "22                     Delhi  \n",
       "23  Hyderabad / Secunderabad  \n",
       "24                      Pune  \n",
       "25                      Pune  \n",
       "26                      Pune  \n",
       "27                      Pune  \n",
       "28     Bengaluru / Bangalore  \n",
       "29     Bengaluru / Bangalore  \n",
       "30                    Others  \n",
       "31                     Delhi  \n",
       "32     Bengaluru / Bangalore  \n",
       "33           Mysoru / Mysore  \n",
       "34  Hyderabad / Secunderabad  \n",
       "35  Hyderabad / Secunderabad  \n",
       "36     Bengaluru / Bangalore  \n",
       "37                 New Delhi  \n",
       "38                   Chennai  \n",
       "39                   Aligarh  \n",
       "40            Salt Lake City  \n",
       "41                      Pune  \n",
       "42     Bengaluru / Bangalore  \n",
       "43                    Mumbai  \n",
       "44                    Indore  \n",
       "45     Bengaluru / Bangalore  \n",
       "46                    MYSORE  \n",
       "47  Hyderabad / Secunderabad  \n",
       "48     Bengaluru / Bangalore  \n",
       "49                    Mumbai  \n",
       "50                            "
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe\n",
    "df = pd.DataFrame({\"Name\":Name,\"Designation\":Designation,\"Company\":Company,\"Skills_they_hire_for\":Skills_they_hire_for,\"Location\":Location},index=list(range(1,len(Location)+1)))\n",
    "print(\"details of Data science recruiters from naukri\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "537f1442",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1079226",
   "metadata": {},
   "source": [
    "Q8. Scrape the details of Highest selling novels.                                                                           \n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/          \n",
    "You have to find the following details:                                                                               \n",
    "A) Book name                                                                                                              \n",
    "B) Author name                                                                                                                \n",
    "C) Volumes sold                                                                                                               \n",
    "D) Publisher                                                                                                                 \n",
    "E) Genre                                                                                                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "aee3bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to driver\n",
    "driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "time.sleep(2)\n",
    "# opening site\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "749c68cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping all data about books\n",
    "all_data = []\n",
    "for i in driver.find_elements(By.XPATH,'//tr/td'):\n",
    "    all_data.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "6547d48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data=all_data[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "77cb76a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "details of Highest selling novels\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book name</th>\n",
       "      <th>Author name</th>\n",
       "      <th>Volumes sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Book name       Author name  \\\n",
       "1                                    Da Vinci Code,The        Brown, Dan   \n",
       "2                 Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "3             Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "4            Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "5                                 Fifty Shades of Grey      James, E. L.   \n",
       "..                                                 ...               ...   \n",
       "96                                           Ghost,The    Harris, Robert   \n",
       "97                      Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "98               Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "99   Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "100  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "    Volumes sold        Publisher                        Genre  \n",
       "1      5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "2      4,475,152       Bloomsbury           Children's Fiction  \n",
       "3      4,200,654       Bloomsbury           Children's Fiction  \n",
       "4      4,179,479       Bloomsbury           Children's Fiction  \n",
       "5      3,758,936     Random House              Romance & Sagas  \n",
       "..           ...              ...                          ...  \n",
       "96       807,311     Random House   General & Literary Fiction  \n",
       "97       794,201          Penguin        Food & Drink: General  \n",
       "98       792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "99       791,507            Orion           Biography: General  \n",
       "100      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating data frame\n",
    "df = pd.DataFrame({'Book name':all_data[1::6],'Author name':all_data[2::6],'Volumes sold':all_data[3::6],'Publisher':all_data[4::6],'Genre':all_data[5::6]},index=list(range(1,101)))\n",
    "print('details of Highest selling novels')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "5e46e958",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b2cbe2",
   "metadata": {},
   "source": [
    "Q9. Scrape the details most watched tv series of all time from imdb.com. Url = https://www.imdb.com/list/ls095964455/          \n",
    "You have to find the following details:                                                                                      \n",
    "A) Name                                                                                                                   \n",
    "B) Year span                                                                                                                  \n",
    "C) Genre                                                                                                                     \n",
    "D) Run time                                                                                                                   \n",
    "E) Ratings                                                                                                                   \n",
    "F) Votes         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "5ec8bd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to driver\n",
    "driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "time.sleep(2)\n",
    "# opening site\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "fbeefdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping name\n",
    "name = []\n",
    "for i in driver.find_elements(By.XPATH,'//h3/a'):\n",
    "    name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "b0db05fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping year span\n",
    "year = []\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"lister-item-year text-muted unbold\"]'):\n",
    "    year.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "a5dbfc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Genre\n",
    "genre = []\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"genre\"]'):\n",
    "    genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "7efe7512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping run time\n",
    "run_time = []\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"runtime\"]'):\n",
    "    run_time.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "43f9d981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping rating\n",
    "rating = []\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"ipl-rating-star small\"]'):\n",
    "    rating.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "6a3d25ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping votes\n",
    "votes = []\n",
    "for i in driver.find_elements(By.XPATH,'//span[@name=\"nv\"]'):\n",
    "    votes.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "0f2d2778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most watched tv shows of all time\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>year-span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,058,820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,152,994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>971,309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>289,644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>249,119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>49,668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>60,699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>195,382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>41,115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>237,752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Name    year-span                     Genre  \\\n",
       "1                   Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "2                   Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "3                  The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "4                    13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "5                           The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                              ...          ...                       ...   \n",
       "96                            Reign  (2013–2017)                     Drama   \n",
       "97   A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "98                   Criminal Minds  (2005–2020)     Crime, Drama, Mystery   \n",
       "99            Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "100      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "     Runtime Rating      Votes  \n",
       "1     57 min    9.2  2,058,820  \n",
       "2     51 min    8.7  1,152,994  \n",
       "3     44 min    8.1    971,309  \n",
       "4     60 min    7.5    289,644  \n",
       "5     43 min    7.6    249,119  \n",
       "..       ...    ...        ...  \n",
       "96    42 min    7.4     49,668  \n",
       "97    50 min    7.8     60,699  \n",
       "98    42 min    8.1    195,382  \n",
       "99    45 min    7.1     41,115  \n",
       "100  572 min    8.6    237,752  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe\n",
    "df = pd.DataFrame({\"Name\":name,\"year-span\":year,\"Genre\":genre,\"Runtime\":run_time,\"Rating\":rating,\"Votes\":votes},index=list(range(1,len(votes)+1)))\n",
    "print('most watched tv shows of all time')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "a3696a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b14ddf5",
   "metadata": {},
   "source": [
    "Q10. Details of Datasets from UCI machine learning repositories. Url = https://archive.ics.uci.edu/                          \n",
    "You have to find the following details:                                                                            \n",
    "A) Dataset name                                                                                                        \n",
    "B) Data type                                  \n",
    "C) Task                  \n",
    "D) Attribute type              \n",
    "E) No of instances            \n",
    "F) No of attribute           \n",
    "G) Year                                                                               \n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code.      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "70190821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to driver\n",
    "driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "time.sleep(2)\n",
    "# opening site\n",
    "driver.get(\"https://archive.ics.uci.edu/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "7e7241a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on all dataset\n",
    "driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/span/b/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "fe228ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping url of dataset\n",
    "url = []\n",
    "for i in driver.find_elements(By.XPATH,'//b/a'):\n",
    "    url.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "ec8d44f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_name = []\n",
    "Data_type = []\n",
    "Task = []\n",
    "Attribute_type = []\n",
    "No_of_instances = []\n",
    "No_of_attribute = []\n",
    "Year = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "c143b7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in url:\n",
    "    driver.get(u)\n",
    "    time.sleep(1)\n",
    "# Extracting Dataset_name \n",
    "    try:\n",
    "        dn = driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/table[1]/tbody/tr/td[1]/p[1]/span[1]/b')      \n",
    "        Dataset_name.append(dn.text)\n",
    "    except NoSuchElementException:\n",
    "        Dataset_name.append('-')    \n",
    "# extracting Data_type\n",
    "    try:\n",
    "        dt = driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[1]/td[2]/p')\n",
    "        Data_type.append(dt.text)\n",
    "    except NoSuchElementException:\n",
    "        Data_type.append('-')\n",
    "# extracting Task\n",
    "    try:\n",
    "        t = driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[3]/td[2]/p')\n",
    "        Task.append(t.text)\n",
    "    except NoSuchElementException:\n",
    "        Task.append('-')  \n",
    "# extracting Attribute_type\n",
    "    try:\n",
    "        at = driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[2]/td[2]/p')\n",
    "        Attribute_type.append(at.text)\n",
    "    except NoSuchElementException:\n",
    "        Attribute_type.append('-')        \n",
    "# extracting No_of_instances\n",
    "    try:\n",
    "        ni = driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[1]/td[4]/p')\n",
    "        No_of_instances.append(ni.text)\n",
    "    except NoSuchElementException:\n",
    "        No_of_instances.append('-')       \n",
    "# extracting No_of_attribute\n",
    "    try:\n",
    "        na = driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[2]/td[4]/p')\n",
    "        No_of_attribute.append(na.text)\n",
    "    except NoSuchElementException:\n",
    "        No_of_attribute.append('-')    \n",
    "# extracting Year \n",
    "    try:\n",
    "        y = driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[2]/td[6]/p')\n",
    "        Year.append(y.text)\n",
    "    except NoSuchElementException:\n",
    "        Year.append('-')          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "434951f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets from UCI machine learning repositories\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_name</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute_type</th>\n",
       "      <th>No_of_instances</th>\n",
       "      <th>No_of_attribute</th>\n",
       "      <th>extracting Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abalone Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Annealing Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anonymous Microsoft Web Data Data Set</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Arrhythmia Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Influenza outbreak event prediction via Twitte...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020-12-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Turkish Music Emotion Dataset Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020-12-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Maternal Health Risk Data Set Data Set</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Classification</td>\n",
       "      <td>N/A</td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Room Occupancy Estimation Data Set</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021-01-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>Image Recognition Task Execution Times in Mobi...</td>\n",
       "      <td>Univariate, Sequential, Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-12-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Dataset_name  \\\n",
       "1                                     Abalone Data Set   \n",
       "2                                       Adult Data Set   \n",
       "3                                   Annealing Data Set   \n",
       "4                Anonymous Microsoft Web Data Data Set   \n",
       "5                                  Arrhythmia Data Set   \n",
       "..                                                 ...   \n",
       "618  Influenza outbreak event prediction via Twitte...   \n",
       "619             Turkish Music Emotion Dataset Data Set   \n",
       "620             Maternal Health Risk Data Set Data Set   \n",
       "621                 Room Occupancy Estimation Data Set   \n",
       "622  Image Recognition Task Execution Times in Mobi...   \n",
       "\n",
       "                               Data_type                 Task  \\\n",
       "1                           Multivariate       Classification   \n",
       "2                           Multivariate       Classification   \n",
       "3                           Multivariate       Classification   \n",
       "4                                    N/A  Recommender-Systems   \n",
       "5                           Multivariate       Classification   \n",
       "..                                   ...                  ...   \n",
       "618                         Multivariate       Classification   \n",
       "619                         Multivariate       Classification   \n",
       "620                                  N/A       Classification   \n",
       "621            Multivariate, Time-Series       Classification   \n",
       "622  Univariate, Sequential, Time-Series           Regression   \n",
       "\n",
       "                 Attribute_type No_of_instances No_of_attribute  \\\n",
       "1    Categorical, Integer, Real            4177               8   \n",
       "2          Categorical, Integer           48842              14   \n",
       "3    Categorical, Integer, Real             798              38   \n",
       "4                   Categorical           37711             294   \n",
       "5    Categorical, Integer, Real             452             279   \n",
       "..                          ...             ...             ...   \n",
       "618               Integer, Real           75840             525   \n",
       "619               Integer, Real             400              50   \n",
       "620                         N/A            1014               7   \n",
       "621                        Real           10129              16   \n",
       "622                        Real            4000               2   \n",
       "\n",
       "    extracting Year  \n",
       "1        1995-12-01  \n",
       "2        1996-05-01  \n",
       "3               N/A  \n",
       "4        1998-11-01  \n",
       "5        1998-01-01  \n",
       "..              ...  \n",
       "618      2020-12-16  \n",
       "619      2020-12-20  \n",
       "620      2020-12-31  \n",
       "621      2021-01-16  \n",
       "622      2020-12-13  \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe \n",
    "df = pd.DataFrame({\"Dataset_name\":Dataset_name,\"Data_type\":Data_type,\"Task\":Task,\"Attribute_type\":Attribute_type,\"No_of_instances\":No_of_instances,\"No_of_attribute\":No_of_attribute,\"extracting Year\":Year},index=list(range(1,len(Year)+1)))\n",
    "print(\"Datasets from UCI machine learning repositories\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "0f5b1157",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378d9dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
